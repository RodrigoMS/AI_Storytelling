{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Parametrização do modelo"
      ],
      "metadata": {
        "id": "H5PJxbX-pkSs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação de biblioteca."
      ],
      "metadata": {
        "id": "J5wKNc7PTIwa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2kb4D1OD83AX"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurar API key."
      ],
      "metadata": {
        "id": "tLt_AvIoTO05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('key')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "Z4VxuIaq9GIt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuração do modelo."
      ],
      "metadata": {
        "id": "X_WDM7cBa-Zq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "    'candidate_count': 1, # Apenas uma resposta.\n",
        "    'temperature': 0.5,    # Temperatura 0 mais criativo, 1 menos criativo.\n",
        "}"
      ],
      "metadata": {
        "id": "BMXj9Oy6aDPK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuração de segurança."
      ],
      "metadata": {
        "id": "uM-JMh4hbOkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = {\n",
        "    'HARASSMENT': 'block_most', #block_none(não bloquear nada) block_few(pouco), block_some(algumas), block_most(maioria)\n",
        "    'HATE': 'block_most',\n",
        "    'SEXUAL': 'block_most',\n",
        "    'DANGEROUS': 'block_some',\n",
        "}"
      ],
      "metadata": {
        "id": "ZPRFn_BwbVvx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Incializa o modelo generativo."
      ],
      "metadata": {
        "id": "99mNqc3yUOQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name='gemini-1.0-pro',\n",
        "                              generation_config=generation_config)\n",
        "                              #safety_settings=safety_settings)"
      ],
      "metadata": {
        "id": "l7hyOKHPqCql"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gerar o texto."
      ],
      "metadata": {
        "id": "EQmx283nU4Zx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content('Era uma vez ...')"
      ],
      "metadata": {
        "id": "5U17NswyVAbo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Armazena o histórico do chat."
      ],
      "metadata": {
        "id": "lKagENJbwDkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "mrdrBXVTvyJO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Função para armazenar as opções de escolha do usuário."
      ],
      "metadata": {
        "id": "t4k1TcXm_BTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alternatives = {}\n",
        "\n",
        "def generate_alternatives(response_text, model):\n",
        "  alternatives = {}\n",
        "\n",
        "  alternatives['A'] = model.generate_content(f'Gere uma frase para continuar esta história (max. 10 palavras): {response.text}').text\n",
        "  alternatives['B'] = model.generate_content(f'Gere uma frase para continuar esta história (max. 10 palavras): {response.text}').text\n",
        "  alternatives['C'] = model.generate_content(f'Gere uma frase para continuar esta história (max. 10 palavras): {response.text}').text\n",
        "  alternatives['D'] = model.generate_content(f'Gere uma frase para continuar esta história (max. 10 palavras): {response.text}').text\n",
        "\n",
        "  print('')\n",
        "  for option, text in alternatives.items():\n",
        "      print(f\"{option} - {text}\")\n",
        "  print('')\n",
        "\n",
        "  return alternatives"
      ],
      "metadata": {
        "id": "We-lvi2K_O8s"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrada do usuário."
      ],
      "metadata": {
        "id": "RDK0PNfrwvyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Response:\n",
        "    def __init__(self, text):\n",
        "        self.text = text\n",
        "\n",
        "response = Response('Era uma vez ...')\n",
        "prompt = ''\n",
        "\n",
        "while prompt != \"FIM\":\n",
        "  response = model.generate_content(f'Continue a escrever a história: {response.text}')\n",
        "\n",
        "  print(response.text)\n",
        "\n",
        "  # Função para armazenar as opções de escolha do usuário.\n",
        "  generate_alternatives(response.text, model)\n",
        "\n",
        "  prompt = input(\"Rumo: \").upper()\n",
        "\n",
        "  response = chat.send_message(prompt)\n",
        "  #prompt = input(\"Rumo: \").upper()\n",
        "\n",
        "  if len(prompt) == 1:\n",
        "    if alternatives is not None:\n",
        "      try:\n",
        "        response.text = f'{response.text} - {alternatives[prompt]}'\n",
        "      except KeyError:\n",
        "        print(\"Opção inválida.\")\n",
        "\n",
        "  else:\n",
        "     # A entrada tem mais de um caractere.\n",
        "     # Quando o usuário deseja inserir outros elementos na história\n",
        "     response.text = f'{response.text} - {prompt}'\n",
        "\n"
      ],
      "metadata": {
        "id": "B76hWpX6v_Ly"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}